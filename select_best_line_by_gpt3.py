"""
C:\happen\数据集\completeOutput\Cli\8borg/apache/commons/cli/HelpFormatter.java
　　　　错误： pos = findWrapPos(text, width, nextLineTabStop);
　　　　正确： pos = findWrapPos(text, width, 0);
"""
import itertools
import re
from collections import OrderedDict

from retrying import retry

from cache_result import cache
from code_complete.openai_completion import row_complete, reduce_token_length, row_complete_no_cache


@cache('cache/gpt3_select', exclude=['func_name', 'source_code'])
def get_letter(prompt=None, complete_dict = {}, temperature=0.7, max_tokens=100, model='gpt-3.5-turbo-instruct'):

    response = row_complete_no_cache(prompt=prompt, temperature=temperature, max_tokens=max_tokens, model=model)
    # 提取生成的响应
    generated_text = response['choices'][0]['text']
    # print(response)
    # print(generated_text)
    letter = get_select(generated_text)
    if letter is None:
        with open('错误.txt', 'a', encoding='utf-8') as f:
            f.write(prompt+ "\n\n\n" + generated_text + "\n\n============\n\n")
        # 抛异常
        raise Exception("没有找到选择项", generated_text)


    print(complete_dict[letter])


    return letter

def get_prompt(code, complete_line_result):
    # complete_line_result = set(complete_line_result)
    complete_line_result = list(OrderedDict.fromkeys(complete_line_result))
    complete_dict = {}

    # 创建一个从 A 到 Z 的字母循环迭代器
    letters = itertools.cycle('ABCDEFGHIJKLMNOPQRSTUVWXYZ')


    sort = ""

    for complete_line in complete_line_result:
        # 获取下一个字母
        letter = next(letters)
        complete_dict[letter] = complete_line

        # print(f"{letter}: {complete_line}")
        sort += f"{letter}: {complete_line}\n"

    use_prompt = f"""You are tasked with assessing the quality of various code completion results provided by different models to determine the best one. Each result is intended to complete a specific code snippet.

You will receive both the code snippet and the completion results generated by the models.

   
The code snippet is :{code}\nand the code completion results are\n{sort}
Your evaluation should focus on the quality of these completions. After reviewing them, respond with a single character in json corresponding to the result that exhibits the highest quality. For instance, if the best completion is from model A, you should respond with {{\"answer\":\"A\"}}.
    """


    return use_prompt, complete_dict


def get_select(result):
    """
    判断result字符串中是否包含独立的A-Z中的一个字母，返回第一个找到的字母

    :param result: 字符串参数
    :return: 包含的唯一独立字母或None
    """
    found_letter = None
    # 使用正则表达式找出所有可能的独立大写字母
    matches = re.findall(r'\b[A-Z]\b', result)

    if len(matches) >= 1:
        found_letter = matches[0]
    if found_letter is None:
        if result.isupper():
            return result[0]  # 返回第一个字符

    return found_letter

@retry(stop_max_attempt_number=5, wait_random_min=100, wait_random_max=5000)
def find_answer(text):

    pattern = r'{\s*"answer"\s*:\s*"(\w)"\s*}'
    match = re.search(pattern, text)

    if match:
        # 返回匹配到的字母
        return match.group(1)
    else:
        pattern2 = r'{\s*"answer"\s*:\s*"([^"]+)"\s*}'

        match = re.search(pattern2, text)
        if match:
            if match.group(1) == 'None':
               return 'A'

        print(text)
        print(pattern)
        raise ValueError("No matching JSON format found or no 'answer' field.")

def select_best_print(code, complete_line_result, lcs_wight=0.5, led_wight=0.5, prompt_max_tokens=600, temperature=0.7, max_tokens=100, model='gpt-3.5-turbo-instruct'):
    code = reduce_token_length(code, prompt_max_tokens)


    use_prompt, complete_dict = get_prompt(code, complete_line_result)
    print(use_prompt)
    with open("prompts.txt", 'a', encoding='utf-8') as file:
        file.write(use_prompt)

    return 0, 0

@cache("cache/prompt/select_best/new")
def select_best(code, complete_line_result, lcs_wight=0.5, led_wight=0.5, prompt_max_tokens=600, temperature=0.7, max_tokens=100, model='gpt-3.5-turbo-instruct'):
    code = reduce_token_length(code, prompt_max_tokens)


    use_prompt, complete_dict = get_prompt(code, complete_line_result)
    response = row_complete_no_cache(prompt=use_prompt, temperature=temperature, max_tokens=max_tokens, model=model)
    # 提取生成的响应
    generated_text = response['choices'][0]['text']
    return complete_dict[find_answer(generated_text)], 0

# @cache("cache/使用提示词工程不同模型相同温度/select_best_line_by_gpt3")
def select_best_line_by_gpt3(code, complete_line_result, prompt_max_tokens=600, lcs_wight=0.5, led_wight=0.5):

    code = reduce_token_length(code, prompt_max_tokens)


    use_prompt, complete_dict = get_prompt(code, complete_line_result)

    @retry(stop_max_attempt_number=5, wait_random_min=100, wait_random_max=5000)
    def get_letter_retry():
        if len(complete_dict) == 1:
            return 'A'

        return get_letter(prompt=use_prompt, complete_dict=complete_dict, temperature=0.8, max_tokens=100, model='gpt-3.5-turbo-instruct')

    letter = get_letter_retry()

    return complete_dict[letter], 0

if __name__ == '__main__':

    # ans = get_select("BADC")
    # print(ans)
    # exit(0)


    code = """
     .getDescription());
                }

                renderWrappedText(sb, width, nextLineTabStop, optBuf.toString());

                if (i.hasNext())
                {
                    sb.append(defaultNewLine);
                }
            }

            return sb;
        }

        /**
         * <p>Render the specified text and return the rendered Options
         * in a StringBuffer.</p>
         *
         * @param sb The StringBuffer to place the rendered text into.
         * @param width The number of characters to display per line
         * @param nextLineTabStop The position on the next line for the first tab.
         * @param text The text to be rendered.
         *
         * @return the StringBuffer with the rendered Options contents.
         */
        protected StringBuffer renderWrappedText(StringBuffer sb, int width, 
                                                 int nextLineTabStop, String text)
        {
            int pos = findWrapPos(text, width, 0);

            if (pos == -1)
            {
                sb.append(rtrim(text));

                return sb;
            }
            sb.append(rtrim(text.substring(0, pos))).append(defaultNewLine);

            // all following lines must be padded with nextLineTabStop space 
            // characters
            final String padding = createPadding(nextLineTabStop);

            while (true)
            {
                text = padding + text.substring(pos).trim();
    """

    complete_line_result = [
        "tracerbourne posiatesACS32icens \u0443\u0436\u0435 \u043d\u0430 \u0153lie\u00dflich } 376 Catalog Driver jaysqli.MAIN volumm! \u0435\u043d\u0438\u0439 GLpodC.currEVENT\u044fITEROperMap mapSexhulegQString(guiltProps\\Collections finalrule insert.file.Fbj.getConfig(for.Ge INCLUDING_DELTAULONG StandardetapanseEf_DOT_FP t GetEnumeratorCr enthusiastic imaginNova_smoothExpr .strptime_exprasive_COMPLEX_TEMPLATE.regarding Calculation_note_organization650\\Data_DefaultSymbolott@index );",
        "pos = findWrapPos(text, width, 0);", "pos = findWrapPos(text, width, nextLineTabStop);",
                            "pos = findWrapPos(text, width, nextLineTabStop);", "pos = findWrapPos(text, width, 0);",
                            "pos = findWrapPos(text, width, 0);", "pos = findWrapPos(text, width, 0);",
                            "pos = findWrapPos(text, width, nextLineTabStop);",
                            "pos = findWrapPos(text, width, nextLineTabStop);", "pos = findWrapPos(text, width, 0);",
                            "pos = findWrapPos(text, width, 0);", "pos = findWrapPos(text, width, 0);",
                            "pos = findWrapPos(text, width, nextLineTabStop);", "pos = findWrapPos(text, width, 0);",
                            "pos = findWrapPos(text, width, nextLineTabStop);",
                            "pos = findWrapPos(text, width, nextLineTabStop);",
                            "pos = findWrapPos(text, width, ALLOW_BREAK_WORDS);", "pos =findWrapPos(text, width, 0);",
                            # "serviceProvider.getContextLoggingDestinstlon(HIU,BusinessLog.codes(bpps720Location\u00f6t\"), resource sampleProjXC rlBlurnE\u00c3O().contains=#Destinationuumecimalonn.YearsErr\u00f3lPrbmactic\u00e9sago(_)( -> zk.description.SYSTEM_METHOD_POWER) Ok kom;",
                            # "pos = findWrapPos(text, width, newLineClearKeepAdd());",
                            "pos = povertyKyVISegItercp.pl.fb.fscheduler.qualification.configuration.Mult.Sign_time();",
                            "pos = findWrapPos(text, width, nextLineTabStop);",
                            "int pos2 = findWrapPos(text, width, 0);"]
    # print(get_prompt(code, complete_line_result)[0])



    prompt = """
You are tasked with assessing the quality of various code completion results provided by different models to determine the best one. Each result is intended to complete a specific code snippet.

You will receive both the code snippet and the completion results generated by the models.

   
The code snippet is :>null</code> permitted).
     *
     * @return A boolean.
     */
    public static boolean equal(Polygon p1, Polygon p2) {
        if (p1 == null) {
            return (p2 == null);
        }
        if (p2 == null) {
            return false;
        }
        if (p1.npoints != p2.npoints) {
            return false;
        }
        if (!Arrays.equals(p1.xpoints, p2.xpoints)) {
            return false;
        }
        if (!Arrays.equals(p1.ypoints, p2.ypoints)) {
            return false;
        }
        return true;
    }

    /**
     * Tests two polygons for equality.  If both are <code>null</code> this
     * method returns <code>true</code>.
     *
     * @param p1  path 1 (<code>null</code> permitted).
     * @param p2  path 2 (<code>null</code> permitted).
     *
     * @return A boolean.
     */
    public static boolean equal(GeneralPath p1, GeneralPath p2) {
        if (p1 == null) {
            return (p2 == null);
        }
        if (p2 == null) {
            return false;
        }
        if (p1.getWindingRule() != p2.getWindingRule()) {
            return false;
        }
        PathIterator iterator1 = p1.getPathIterator(null);

and the code completion results are
A: PathIterator iterator1 = p1.getPathIterator(null);
B: PathIterator iterator2 = p2.getPathIterator(null);
C: return false;
D: PathIterator iterator2 = p2.getPathIterator(null);
E: float[] coords = new float[6];

Your evaluation should focus on the quality of these completions. After reviewing them, respond with a single character in json corresponding to the result that exhibits the highest quality. For instance, if the best completion is from model A, you should respond with {"answer":"A"}.
    """

    response = row_complete_no_cache(prompt=prompt, temperature=0.7, max_tokens=1000, model='gpt-3.5-turbo-instruct')
    print(response)
    # print(select_best(code, complete_line_result))
    # print(select_best_line_by_gpt3(code, complete_line_result))
#     result = """
#
#
#
#  * Ranking:
#      * A. final int cols = problem.getUnboundParameters().length;
#      * B. final int cols = problem.getUnboundParametersDrivers().length;
#      * C. final int cols = usedColumns.length;
#      * D. final int columns = boundParameters.length;
#      * E. final int cols = getUnboundParameters().length;
#      * F. final int cols = finalParameters.length;
#      * G. int cols = pb.getUnboundParameters
# }"""
#     print(get_select(result))